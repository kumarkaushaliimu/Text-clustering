{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjrfZIdddZO4ZUU+g2qrKK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVuKtFFCTlAZ"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries\n",
        "import numpy  as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text  import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Means\n",
        "from sklearn import cluster\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "# Visualization and Analysis\n",
        "import matplotlib.pyplot  as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from wordcloud import WordCloud\n"
      ],
      "metadata": {
        "id": "2hNDpgbM1LxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import spacy\n",
        "import multiprocessing\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk8y7A5ZA-qU",
        "outputId": "3c4a5069-b8ee-4f37-eb3b-264531bc0e94"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyRdyBIcF092",
        "outputId": "3f3d8b6c-6d24-40a2-abf7-0316a5c3e9d0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing dataset\n",
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "metadata": {
        "id": "-GWTUY-T1Uwt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the 20Newsgroup dataset \n",
        "df = fetch_20newsgroups(subset='all',remove=('headers', 'footers', 'quotes'),shuffle=True, random_state=102)"
      ],
      "metadata": {
        "id": "KpMXZFDO1U0A"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No of labels\n",
        "labels = df.target\n",
        "n=len(np.unique(labels))\n",
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rNpNQoD1U2T",
        "outputId": "0392bcea-7436-4ac0-ee84-4ba3e75c5b6a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = df.data"
      ],
      "metadata": {
        "id": "S7P19dEPBhJ_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceaGpMzaBhM4",
        "outputId": "a41c6b9a-d592-4275-a10e-a1f685244a04"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['You definetly are in need of a shrink, loser!',\n",
              " \"Software that comes together with the VideoBlaster\\nis designed to work together with the SoundBlaster\\n(from the same manufacturer).\\n\\nSince I do not own a SoundBlaster: is there a possibility\\nto use the PC Speaker driver to play audio files for\\nthe VideoBlaster (.AVI = audio video interleave files) ?\\n\\nI think what I should have is a device driver for\\nthe Media Player that controls the PC Speaker Driver\\ninstead of the SoundBlaster card (something like MCISPKR.DRV).\\n\\nHas anybody heard of such a driver?\\nOr am I on the wrong track?\\n\\nAny information on this appreciated!\\n\\n(Please send e-mail, since I don't watch this group regularly.)\\n\",\n",
              " 'I have an old IBM PC-XT motherboard which has TWO banks\\nof dip switches (eight switches per bank).  I need to \\nknow which switch is required to install a hard disk.\\n\\nDoes anyone have any archived documentation that would\\nhelp me?  \\n                                            \\nThanks -jim-  jimd@cae.prds.cdx.mot.com ']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0].replace('[^\\w\\s]','')        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LDgveb74DAXv",
        "outputId": "872dd618-830f-49b8-8500-f55b999c2ee4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You definetly are in need of a shrink, loser!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for preprocessing\n",
        "def pre_processing(docs):\n",
        "  stop = stopwords.words('english')\n",
        "\n",
        "  for doc in docs:\n",
        "      raw_text = doc.lower()\n",
        "      doc_punc = doc.replace('[^\\w\\s]','')        \n",
        "      # tokenization\n",
        "      tokens_text = word_tokenize(raw_text)\n",
        "      # remove stopwords\n",
        "      stopped_tokens_text = [i for i in tokens_text if not i in stop]\n",
        "      # remoce digis and one-charcter word\n",
        "      doc = [token for token in stopped_tokens_text if not token.isnumeric()]\n",
        "      doc = [token for token in stopped_tokens_text if len(token) > 1]\n",
        "      # you could always add some new preprocessing here\n",
        "      yield doc\n"
      ],
      "metadata": {
        "id": "DTEIVoLVBhPs"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess all the documents in the corpus\n",
        "Vocab_v1 = list(pre_processing(corpus))"
      ],
      "metadata": {
        "id": "bywLYdCtFYSc"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(Vocab_v1))\n",
        "print(Vocab_v1[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpmsGRM9FYXI",
        "outputId": "73918467-d54a-454e-fceb-852e0804bad4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18846\n",
            "['definetly', 'need', 'shrink', 'loser']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Word2Vec model\n",
        "\n",
        "# Initialize and train the model. \n",
        "print(\"Training the Word2Vec model...\");\n",
        "w2v_model = Word2Vec(Vocab_v1, size=100, min_count = 20, window = 5, sample = 1e-3)\n",
        "# calling init_sims to make the model more memory efficient\n",
        "w2v_model.init_sims(replace=True);\n",
        "# Save the model\n",
        "model_name = \"model_word2vec_20newsGroup\";\n",
        "w2v_model.save(model_name);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHxiACCFGMWT",
        "outputId": "b76a28a3-b405-4429-cad3-a629ad3f4584"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the Word2Vec model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = w2v_model.wv.syn0;\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aibLq_tFHp1e",
        "outputId": "35b0ed5e-900b-42ec-90e0-34dcdafa4e1e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-885e4218ff0c>:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  word_vectors = w2v_model.wv.syn0;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vectors[0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CFJtJ7OHr6I",
        "outputId": "9bcc4a68-3975-47cc-9419-a1ccd5b06851"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cluster the text using KMeans\n",
        "num_clusters = 20\n",
        "kmeans_clustering = KMeans(n_clusters = num_clusters)\n",
        "clusters = kmeans_clustering.fit_predict(word_vectors)\n",
        "centers = kmeans_clustering.cluster_centers_"
      ],
      "metadata": {
        "id": "_hv543b4GMY_"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Silhoutte Score\n",
        "#\n",
        "score = silhouette_score(word_vectors, kmeans_clustering.labels_, metric='euclidean')\n",
        "#\n",
        "# Print the score\n",
        "#\n",
        "print('Silhouetter Score: %.3f' % score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz9-ZqnFFYb5",
        "outputId": "b44a28f0-0fee-4906-9661-46375a77844e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouetter Score: 0.121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cZDLjFNp5ejg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}